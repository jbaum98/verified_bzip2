\documentclass[11pt]{thesis}

\title{Towards a Verified Bzip2: A Functional Specification for Burrows-Wheeler}
\author{Jake Waksbaum}
\date{May 6, 2019}

\begin{document}

\maketitle

\section{Introduction}
\label{sec:intro}

The Burrows-Wheeler transform (BWT) is an invertible transformation
that makes a string more amenable to compression by other methods
\cite{bw}. The forwards transform is straightforward to describe: for
a string of length \(n\), form the \(n \times n\) rotaion matrix of all
cyclic shifts of the original string, sort it lexicographically, and
take the last column of the matrix. In addition, we note that index
where the original string appears in the sorted rotation matrix. As
shown in \cref{fig:bw_ex}, applying the algorithm to the string
\texttt{abracadabra!} produces the new string \texttt{ard!rcaaabb} and
the index \texttt{3}. The transformation tends to produce runs like
the three \texttt{a}s or the two \texttt{b}s, and it is this feature
that makes the resulting string easier to compress. Although it is not
at all obvious, the transformed string, together with the index,
provide enough information to recover the the original string. BWT is
discussed more in \cref{sec:bwt}.

\begin{figure}
  \centering
  \begin{tt}
  \begin{tabular}{rc}
    0  & abracadabra! \\
    1  & bracadabra!a \\
    2  & racadabra!ab \\
    3  & acadabra!abr \\
    4  & cadabra!abra \\
    5  & adabra!abrac \\
    6  & dabra!abraca \\
    7  & abra!abracad \\
    8  & bra!abracada \\
    9  & ra!abracadab \\
    10 & a!abracadabr \\
    11 & !abracadabra
  \end{tabular}
  $\rightarrow$
  \begin{tabular}{rc}
    0  & !abracadabr\textbf{a} \\
    1  & a!abracadab\textbf{r} \\
    2  & abra!abraca\textbf{d} \\
    \textit{3} & \textit{abracadabra\textbf{!}} \\
    4  & acadabra!ab\textbf{r} \\
    5  & adabra!abra\textbf{c} \\
    6  & bra!abracad\textbf{a} \\
    7  & bracadabra!\textbf{a} \\
    8  & cadabra!abr\textbf{a} \\
    9  & dabra!abrac\textbf{a} \\
    10 & ra!abracada\textbf{b} \\
    11 & racadabra!a\textbf{b}
  \end{tabular}
  \end{tt}
  \caption{BWT acting on \texttt{abracadabra!}}
  \label{fig:bw_ex}
\end{figure}

Bird and Mu \cite{birdmu,pearls} analyze the Burrows-Wheeler algorithm
in a functional setting. They express the algorithm as the composition
of many smaller functions, and then derive an expression for the
inverse transform from the specification that it inverts the forwards
transform. In addition to providing an intuitive derivation of the
inverse transform, this provides the outline of a proof of the
correctness of the Burrows-Wheeler algorithm. We give our version of
their derivation in \cref{sec:forwards_BWT,sec:inverse_BWT}.

Our main contribution is a formalization in the Coq proof assistant of
the BWT, together with a machine-checked proof that our implementation
is correct. Specifically, we implement the functions
$\mathtt{bwp} : \mathtt{list}~A \to \mathtt{list}~A$ and
$\mathtt{bwn} : \mathtt{list}~A \to \mathbb{N}$ to produce the string
and index part of the BWT respectively, and the function
$\mathtt{unbwt} : \mathbb{N} \to \mathtt{list}~A \to \mathtt{list}~A$ to
reverse the transform, and we prove the following theorem:
\begin{theorem}[unbwt\_correct]
  \label{thm:unbwt_correct}
  For all lists $l$,
  \begin{equation*}
    \mathtt{unbwt}~(\mathtt{bwn}~l)~(\mathtt{bwp}~l) = l
  \end{equation*}
\end{theorem}
The implementation of the functions and the outline of the proof are
based on Bird et~al.'s derivations.

The implementation is useful in its own right as a functional
specification for a potential verified implementation of a program
that relies on Burrows-Wheeler \cite{appel-func-spec}. But more
generally, this provides evidence that Bird's approach of program
calculation, in which programs are derived from their specifications
via algebraic manipulations, is useful for proving the correctness of
algorithms in a machine-checked setting. Bird has applied this
approach to greedy algorithms, the Boyer-Moore algorithm, the
Knuth-Morris-Pratt algoirthm, Sudoku solvers, arithmetic coding, and
the Schorr-Waite algorithm, the Johnson-Trotter algorithm, and many
more problems \cite{pearls}.

As a part of the proof of \Cref{thm:unbwt_correct}, we implemented
radix-sort and proved its correctness,
\begin{theorem}[radixsort\_correct]
  \label{thm:radixsort_correct}%
  For all lists $l$,
  \begin{equation*}
    \mathtt{Sorted}~(\mathtt{radixsort}~l) \land \mathtt{Permutation}~(\mathtt{radixsort}~l)~l
  \end{equation*}
\end{theorem}
and proved that any two stable sorts are interchangable,
\begin{theorem}[stable\_sort\_unique]
  \label{thm:radixsort_correct}%
  For all functions $f, g : \mathtt{list}~A \to \mathtt{list}~A$,
  \begin{gather*}
    (\forall l,~\mathtt{Sorted}~(f~l) \land \mathtt{StablePermutation}~(f~l)~l) \implies \\
    (\forall l,~\mathtt{Sorted}~(g~l) \land \mathtt{StablePermutation}~(g~l)~l) \implies \\
    \forall l,~f~l = g~l
  \end{gather*}
\end{theorem}
This in turn required developing suitable definitions for
\texttt{Sorted}, \texttt{Permutation}, and \texttt{StablePermutation}.
We explored multiple definitions for each of these properties, and
proved equivalence between them.

The rest of this paper is organize as follows. \Cref{sec:bwt} details
the history of the BWT and its applications. \Cref{sec:ord} defines
what we need to know about a type $A$ to sort a $\mathtt{list}~A$ as a
part of BWT. Following Bird et~al., \cref{sec:forwards_BWT} defines
the implementation of the forwards BWT in Coq, and
\cref{sec:inverse_BWT} derives an implementation of the inverse BWT
via program calculation. \Cref{sec:sorted_perm_stable} provides
multiple definitions of \texttt{Sorted}, \texttt{Permutation}, and
\texttt{StablePermutation}, and proves equivalence between them.
\Cref{sec:sort} implements insertion sort and radixsort, and proves
their correctness. \Cref{sec:BWT_proof} more formally proves the
theorems about the BWT mentioned in previous sections, including
\Cref{thm:unbwt_correct}.

The full source code can be found at
\url{https://github.com/jbaum98/verifed_bzip2/tree/2019-05-06}.

\section{Burrows-Wheeler}
\label{sec:bwt}

The Burrows-Wheeler transform was originally introduced as a pass in a
compression algorithm. First the input is transformed with BWT, which
tends to group together characters. The intuition for why this happens
is that all adjacent characters in the output string are followed in
the input string by characters that are adjacent in the sorted first
column. If there is any correlation between a character and the
character preceding it, bringing together the characters in the first
column will tend to bring together similar characters in the last
column.

The next pass is a Move-to-Front (MTF) encoding, in which a character
is represented by the number of different characters encountered since
the last occurence of this character. This creates many runs of zeroes
from the runs in the output of BWT. On English texts, often 50-60\% of
the values produced by the MTF pass are zeroes
\cite{fenwick2007,bw-analysis}. Often a Run-Length Encoding (RLE) pass
is then used to encode only the runs of zeroes with their lengths,
using a bijective base-2 encoding \cite{bw-analysis, tsai_2016}.
Finally, some sort of zeroth-order coder like a Huffman coder is used.

BWT is also at the heart of algorithms that exploit the relationship
between the rotation matrix in BWT and the suffix array data structure
in order to search for patterns in a compressed text
\cite{ferragina_index}.

\section{Orders and Preorders}
\label{sec:ord}

Although it is commonly demonstrated on strings, the BWT can be
applied to any list whose elements are comparable. To make that
precise, if we have a type $A$ and a relation on that type $\le$, we say
that this forms a preorder on $A$ when $\le$ is reflexive and transitive, that is
$x \le x$ for all $xA$, and
\begin{equation*}
  x \le y \implies y \le z \implies x \le z
\end{equation*}
for all $x,y,z$.

We say that we have a \textit{total} preorder if for any two elements
$x$ and $y$, $x \le y \lor y \le x$.

We say that we have a \textit{decidable} preorder if we have a
decision procedure for determining whether $x \le y$ or $x \not\le y$.

We represent a total, decidable preorder on type with the
\texttt{Preord} typeclass in Coq:
\lstinputlisting[firstline=9, lastline=14]{../theories/BWT/Sorting/Ord.v}
We do not explicitly require reflexivity because it follows from totality.

From $\le$, we can define $x \ge y \coloneqq y \le x$, $x < y \coloneqq
\lnot (y \le x)$, and $x > y \coloneqq \lnot (x \le y)$, and prove
transitivity and reflexivity where appropriate.

We can also define $x \equiv y \coloneqq x \le y \land y \le x$. $\equiv$ is a
decidable equivalence relation, which means it is reflexive,
transitive, and symmetric. The builtin class \texttt{EqDec} is used to
describe types with decidable equivalence relations, so for any
\texttt{Preord} instance we have the \texttt{EqDec} instance
\texttt{Preord\_EqDec} using \texttt{eqv\_dec}:
\lstinputlisting[firstline=116, lastline=120,
  widthgobble=2]{../theories/BWT/Sorting/Ord.v}
In Coq, the notation \texttt{===} is used for the relation of an
\texttt{EqDec} instance and \texttt{==} for the decision procedure of
an \texttt{EqDec} instance.

We say that we have a total, decidable \textit{order} when we have
that for all $x$ and $y$,
\begin{equation*}
  x \equiv y \implies x = y
\end{equation*}
that is, the induced equivalence relation of the preorder ($\equiv$)
implies Leibniz equality ($=$). We use the \texttt{Ord} class in Coq for this:
\lstinputlisting[firstline=175, lastline=176,
  widthgobble=2]{../theories/BWT/Sorting/Ord.v}
For the BWT, we require an \texttt{Ord} instance for $A$, but for other parts of the proof, such as sorting, \texttt{Preord} will suffice.

\section{The Forwards BWT}
\label{sec:forwards_BWT}

First, we define left and right rotations of a list.
\lstinputlisting[widthgobble=2, firstline=17, lastline=22]{../theories/BWT/Lib/List.v}
\lstinputlisting[widthgobble=2, firstline=16, lastline=21]{../theories/BWT/Rotation/Rotation.v}
\lstinputlisting[widthgobble=2, firstline=23, lastline=28]{../theories/BWT/Rotation/Rotation.v}

Now we can produce the rotation matrix by repeatedly applying \texttt{lrot}.
\lstinputlisting[widthgobble=2, firstline=11, lastline=18]{../theories/BWT/Lib/Iterate.v}
\lstinputlisting[widthgobble=2, firstline=17, lastline=18]{../theories/BWT/Rotation/Rots.v}

Finally, we produce the transformed string by taking the last column
of the sorted rotation matrix. \texttt{lexsort} sorts the rotation
matrix lexicographically using the \texttt{Ord} instance; we will
discuss it's implementation in \cref{sec:sort}.
\lstinputlisting[firstline=31,
  lastline=35]{../theories/BWT/BurrowsWheeler.v}
Note that in order to ensure that $\mathtt{last}$ is total, it takes
an extra argument to return in the case of an empty list.

We also need to find the index in the sorted rotation matrix where the
original string appears.
\lstinputlisting[firstline=12, lastline=19]{../theories/BWT/Lib/FindIndex.v}
\lstinputlisting[firstline=73, lastline=74]{../theories/BWT/BurrowsWheeler.v}

\section{The Inverse BWT}
\label{sec:inverse_BWT}

Now we have to construct a function \texttt{unbwt} such that for all $l$,
\begin{equation}
  \mathtt{unbwt}~(\mathtt{bwn}~l)~(\mathtt{bwp}~xs) = l
  \label{eq:unbwt}
\end{equation}
If we could recreate the entire sorted rotation matrix from
$\mathtt{bwp}~l$, it would be simple to recover $x$ by indexing into
the matrix at $\mathtt{bwn}~x$.

More precisely, suppose we had a function function \texttt{recreate}
such that
\begin{equation}
  \mathtt{recreate}~(\mathtt{bwp}~l) = \mathtt{lexsort}~(\mathtt{rots}~l)
  \label{eq:recreate}
\end{equation}
Then, we could define \texttt{unbwt} as
\begin{lstlisting}
Definition unbwt (i : nat) (l : list A) : list A :=
  nth i (recreate l) l.
\end{lstlisting}
and \Cref{eq:unbwt} would follow directly from the following theorem:
\begin{theorem}[bwn\_correct]
  For every non-empty list $l$,
  \begin{equation*}
    (\mathtt{lexsort}~(\mathtt{rots}~l))_{(\mathtt{bwn}~l)} = l
  \end{equation*}
\end{theorem}

How, then, do we implement \texttt{recreate}? We will recreate the
sorted rotation matrix column by column, so \verb|recreate j| will
recreate the first \verb|j| columns of the sorted rotation matrix.
\begin{verbatim}
Definition cols (j : nat) (l : list A) : list A := map (firstn j) l.

Theorem recreate_correct_ind : forall j l,
    j <= length l ->
    recreate j (bwp l) = cols j (lexsort (rots l)).
\end{verbatim}

To derive an implementation of \verb|recreate| from this correctness
specification, we need an expression for \verb|recreate 0| and
\verb|recreate (S j)|. We can substitute for \verb|j| on the
right-hand side and manipulate that expression algebraically until it
is in the form \verb|_ (bwp l)|. Then we can define \verb|recreate 0|
and \verb|recreate (S j)| to be precisely the \verb|_|, and by
running our derivation in reverse, we obtain a proof for the base and
inductive cases that uses only rewrites.

We start with the base case, \verb|recreate 0|:
\begin{verbatim}
  cols 0 (lexsort (rots l))
= { by unfold cols }
  map (firstn 0) (lexsort (rots l))
= { by firstn_O}
  map (const []) (lexsort (rots l))
= { by map_const }
  repeat [] (length (lexsort (rots l)))
= { by bwp_length, rots_length, lexsort_length }
  repeat [] (length (bwp l))
= { by map_const }
  map (const []) (bwp l)
\end{verbatim}

From this, we can define \verb|recreate 0 l = map (const []) l| and
we already have the proof for the base case of the correctness
specification.

For the inductive case, we have the expression
\begin{verbatim}
  cols (S j) (lexsort (rots l))
\end{verbatim}
on the right-hand side. Our plan is to express \verb|cols (S j)|
in terms of \verb|cols j|, and then to use the inductive hypothesis
\begin{verbatim}
  cols j (lexsort (rots l)) = recreate j
\end{verbatim}
to produce a well-formed recursive definition.

One way to do this is to say that taking the first \verb|S j| columns
of a matrix is the same as moving the first column to the back, taking
the first \verb|j| columns, and then sticking the last column back on
the front:
\begin{verbatim}
  cols (S j) l = prepend_col (map last (map lrot l)) (cols j (map lrot l))
\end{verbatim}
If we substitute \verb|map rrot l| for \verb|l| we find a simpler
expression
\begin{verbatim}
  cols (S j) (map rrot l) = prepend_col (map last l) (cols j l)
\end{verbatim}

Now we would like to find a way of introducing a \verb|map rrot|
before the \verb|lexsort (rots l)|. The insight here is that we can
assume that \verb|lexsort| is actually a radix-sort. That is, that
\begin{verbatim}
lexsort xs = rep (length xs) (hdsort ∘ map rrot) xs
\end{verbatim}
where \verb|hdsort| sorts the matrix stably on the the first column
and \verb|rep| is defined as
\begin{verbatim}
Fixpoint rep (f : A -> A) (n : nat) (z : A) : A :=
  match n with
  | O => z
  | S m => f (rep f m z)
  end.
\end{verbatim}

We can do this because there is only one way to sort the matrix, so
assuming \verb|lexsort| and the radix-sort are correct, they must be
doing the same thing. We will specify precisely when and why this is
valid later.

Stepping back, it is important to say that this insight, whether
explicitly stated or not, is always the crucial step in inverting the
Burrows-Wheeler transform. Because radix-sort only needs one column at
a time, this transformation will allow us to reconstruct the sorted
rotation matrix one column at a time.

In seeking to introduce an extra \verb|map rrot| term, we can note
that rotating and sorting an extra time doesn't change anything when
we are sorting the rotation matrix. This works because rotating the
last column to the front produces a matrix that is sorted on its last
\verb|n - 1| characters, so sorting stably on the first column will
re-sort the matrix. Crucially though, rotating the last column
forwards also permutes the entire matrix, so in addition to having a
sorted list, we have a sorted list of the same elements.

More precisely, we can characterize how \verb|map rrot| permutes
\verb|rots|
\begin{verbatim}
map rrot (rots x) = rrot (rots x)
\end{verbatim}

Using that we can show
\begin{verbatim}
  lexsort (rots x)
= { because rrot permutes its elements }
  lexsort (rrot (rots x))
= { because hdsort permutes its elements }
  lexsort (hdsort (rrot (rots x)))
= { radix-sort }
  rep n (hdsort ∘ rrot) (hdsort (rrot (rots x)))
= { rep_absorb_r }
  rep (S n) (hdsort ∘ rrot) (rots x)
= { rep_split_l }
  hdsort (rrot (rep n (hdsort ∘ rrot) (rots x)))
= { radix-sort }
  hdsort (rrot (lexsort (rots x)))
\end{verbatim}

From here we can calculate
\begin{verbatim}
  cols (S j) (lexsort (rots l))
= cols (S j) (hdsort (map rrot (lexsort (rots l))))
= { hdsort commutes with cols (S j) }
  hdsort (cols (S j) (map rrot (lexsort (rots l))))
= { reduce cols (S j) }
  hdsort (prepend_col (map last (lexsort (rots l))) (cols j (lexsort (rots l)))
= { by IH and def of bwp }
  hdsort (prepend_col (bwp l) (recreate j (bwp l)))
= (fun x => hdsort (prepend_col x (recreate j x))) bwp
\end{verbatim}

We can use this to define \verb|recreate|:
\begin{verbatim}
Fixpoint recreate (j : nat) (l : list A) : list (list A) :=
  match j with
  | O    => map (const []) l
  | S j' => hdsort (prepend_col l (recreate j' l))
  end.
\end{verbatim}

\section{\texttt{Sorted}, \texttt{Permutation}, and \texttt{StablePermutation}}
\label{sec:sorted_perm_stable}

In this section we prove the lemmas from the previous section:
\begin{enumerate}
\item
\begin{verbatim}
map rrot (rots x) = rrot (rots x)
\end{verbatim}

\item \verb|hdsort| commutes with \verb|cols (S j)|
  This proof is cool because in theory it can be proven via
  parametricity, but that's a metatheorem in Coq.

\item
\begin{verbatim}
cols (S j) (map rrot l) = prepend_col (map last l) (cols j l)
\end{verbatim}
\end{enumerate}

\section{Insertion Sort, Radixsort, and \texttt{lexsort}}
\label{sec:sort}

\section{Proving BWT Correct}
\label{sec:BWT_proof}

\printbibliography{}

\end{document}

We prove this using a few lemmas about \texttt{findIndex},
\texttt{lexsort}, and \texttt{rots}.

\begin{lemma}[findIndex\_correct]
  For all elements $x$, lists $l$,
  \begin{equation*}
    (\exists y \in l,~x \equiv y) \implies l_{(\mathtt{findIndex}~x~xs)} \equiv x
  \end{equation*}
  \begin{proof}
    This follows by induction on $xs$: At every step, either the
    current element is equivalent to $x$ and we return $0$, or there
    must be such a $y$ in the rest of the list.
  \end{proof}
\end{lemma}

\begin{lemma}[orig\_in\_sorted\_rots]
  For every non-empty list $l$,
  \begin{equation*}
    \exists y \in \mathtt{lexsort}~(\mathtt{rots}~l),~x = y
  \end{equation*}
  \begin{proof}
    Clearly $l$ is in $\mathtt{rots}~l$ at index 0, and because
    \texttt{lexsort} produces a permutation of its input, $l$ must be
    in $\mathtt{lexsort}~(\mathtt{rots}~l)$ as well.
  \end{proof}
\end{lemma}

\begin{theorem}[bwn\_correct]
  For every non-empty list $xs$,
  \begin{equation*}
    (\mathtt{lexsort}~(\mathtt{rots}~xs))_{(\mathtt{bwn}~xs)} = xs
  \end{equation*}
  \begin{proof}
    This follows from \textsf{findIndex\_correct} if we can show that
    $\exists y \in xs,~x = y$, which we have by \textsf{orig\_in\_sorted\_rots}.
  \end{proof}
\end{theorem}
